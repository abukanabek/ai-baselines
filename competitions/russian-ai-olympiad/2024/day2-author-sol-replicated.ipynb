{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:16.595953Z",
     "iopub.status.busy": "2025-11-13T06:28:16.595679Z",
     "iopub.status.idle": "2025-11-13T06:28:20.959504Z",
     "shell.execute_reply": "2025-11-13T06:28:20.958872Z",
     "shell.execute_reply.started": "2025-11-13T06:28:16.595933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# https://cups.online/ru/tasks/2461\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:20.961595Z",
     "iopub.status.busy": "2025-11-13T06:28:20.960757Z",
     "iopub.status.idle": "2025-11-13T06:28:21.028852Z",
     "shell.execute_reply": "2025-11-13T06:28:21.028023Z",
     "shell.execute_reply.started": "2025-11-13T06:28:20.961548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:21.030202Z",
     "iopub.status.busy": "2025-11-13T06:28:21.029922Z",
     "iopub.status.idle": "2025-11-13T06:28:21.042057Z",
     "shell.execute_reply": "2025-11-13T06:28:21.041425Z",
     "shell.execute_reply.started": "2025-11-13T06:28:21.030173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    'no_relevant': 0,\n",
    "    'relevant_minus': 1,\n",
    "    'relevant': 2,\n",
    "    'relevant_plus': 3,\n",
    "}\n",
    "\n",
    "idx2class = {v: k for k, v in class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:21.043787Z",
     "iopub.status.busy": "2025-11-13T06:28:21.043528Z",
     "iopub.status.idle": "2025-11-13T06:28:21.057312Z",
     "shell.execute_reply": "2025-11-13T06:28:21.056696Z",
     "shell.execute_reply.started": "2025-11-13T06:28:21.043769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# posts = pd.read_parquet(\"/kaggle/input/russian-ai-olympiad-2024-b/items.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:21.058243Z",
     "iopub.status.busy": "2025-11-13T06:28:21.058032Z",
     "iopub.status.idle": "2025-11-13T06:28:21.072026Z",
     "shell.execute_reply": "2025-11-13T06:28:21.071460Z",
     "shell.execute_reply.started": "2025-11-13T06:28:21.058219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# itemId2idx = dict()\n",
    "# for i, row in tqdm(posts.iterrows(), total=len(posts)):\n",
    "#     itemId2idx[row['itemId']] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:21.073182Z",
     "iopub.status.busy": "2025-11-13T06:28:21.072740Z",
     "iopub.status.idle": "2025-11-13T06:28:21.084931Z",
     "shell.execute_reply": "2025-11-13T06:28:21.084212Z",
     "shell.execute_reply.started": "2025-11-13T06:28:21.073155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"/kaggle/input/russian-ai-olympiad-2024-b/train.csv\")\n",
    "# test = pd.read_csv(\"/kaggle/input/russian-ai-olympiad-2024-b/test.csv\")\n",
    "# subm = pd.read_csv(\"/kaggle/input/russian-ai-olympiad-2024-b/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:21.085787Z",
     "iopub.status.busy": "2025-11-13T06:28:21.085615Z",
     "iopub.status.idle": "2025-11-13T06:28:21.101377Z",
     "shell.execute_reply": "2025-11-13T06:28:21.100739Z",
     "shell.execute_reply.started": "2025-11-13T06:28:21.085772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train = train[~train['target'].isin(['doubles', 'unavailable'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:21.102386Z",
     "iopub.status.busy": "2025-11-13T06:28:21.102162Z",
     "iopub.status.idle": "2025-11-13T06:28:21.116181Z",
     "shell.execute_reply": "2025-11-13T06:28:21.115514Z",
     "shell.execute_reply.started": "2025-11-13T06:28:21.102359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "\n",
    "# def get_data_from_posts(row):\n",
    "#     idx1, idx2 = itemId2idx[row['leftItemId']], itemId2idx[row['rightItemId']]\n",
    "#     post1, post2 = posts.iloc[idx1], posts.iloc[idx2]\n",
    "\n",
    "#     if row.get('target') is not None:\n",
    "#         row['target'] = class2idx[row['target']]\n",
    "    \n",
    "#     row['text1'] = post1['title']\n",
    "    \n",
    "#     row['text2'] = post2['title']\n",
    "\n",
    "#     row['same_author'] = 1 if post1['authorId'] == post2['authorId'] else 0\n",
    "    \n",
    "#     return row\n",
    "    \n",
    "\n",
    "# train = train.progress_apply(get_data_from_posts, axis=1)\n",
    "# train.drop(columns=['leftItemId', 'rightItemId'], inplace=True)\n",
    "\n",
    "# test = test.progress_apply(get_data_from_posts, axis=1)\n",
    "# test.drop(columns=['leftItemId', 'rightItemId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:21.117164Z",
     "iopub.status.busy": "2025-11-13T06:28:21.116928Z",
     "iopub.status.idle": "2025-11-13T06:28:21.128819Z",
     "shell.execute_reply": "2025-11-13T06:28:21.128200Z",
     "shell.execute_reply.started": "2025-11-13T06:28:21.117137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train.to_parquet(\"new_train.parquet\")\n",
    "# test.to_parquet(\"new_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:21.131895Z",
     "iopub.status.busy": "2025-11-13T06:28:21.131657Z",
     "iopub.status.idle": "2025-11-13T06:28:22.725324Z",
     "shell.execute_reply": "2025-11-13T06:28:22.724481Z",
     "shell.execute_reply.started": "2025-11-13T06:28:21.131857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"/kaggle/input/russian-ai-olympiad-2024-b/new_train.parquet\")\n",
    "test = pd.read_parquet(\"/kaggle/input/russian-ai-olympiad-2024-b/new_test.parquet\")\n",
    "subm = pd.read_csv(\"/kaggle/input/russian-ai-olympiad-2024-b/sample_submission.csv\")\n",
    "\n",
    "train['text'] = train['text1'] + train['text2']\n",
    "test['text'] = test['text1'] + test['text2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:22.726652Z",
     "iopub.status.busy": "2025-11-13T06:28:22.726283Z",
     "iopub.status.idle": "2025-11-13T06:28:22.872324Z",
     "shell.execute_reply": "2025-11-13T06:28:22.871742Z",
     "shell.execute_reply.started": "2025-11-13T06:28:22.726629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, _ = train_test_split(train, test_size=0.6, stratify=train['target'], random_state=42)\n",
    "\n",
    "train, valid = train_test_split(train, test_size=0.05, stratify=train['target'], random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:22.873266Z",
     "iopub.status.busy": "2025-11-13T06:28:22.873043Z",
     "iopub.status.idle": "2025-11-13T06:28:27.580445Z",
     "shell.execute_reply": "2025-11-13T06:28:27.579702Z",
     "shell.execute_reply.started": "2025-11-13T06:28:22.873248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade protobuf==3.20.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:27.581720Z",
     "iopub.status.busy": "2025-11-13T06:28:27.581460Z",
     "iopub.status.idle": "2025-11-13T06:28:59.976481Z",
     "shell.execute_reply": "2025-11-13T06:28:59.975786Z",
     "shell.execute_reply.started": "2025-11-13T06:28:27.581697Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3131d7ebcb004f1ab27d138f1bf8d395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1240c141a274438bd3904f2e0ff2f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bc3606cdff43e5a88d34016b69243a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ca7cffc91f4b9d882bb521b5282f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 06:28:38.188598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763015318.365443      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763015318.410215      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206b9a1e97ce457d81f64aec9a4fdf7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-sentence and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_checkpoint = \"DeepPavlov/rubert-base-cased-sentence\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:28:59.977879Z",
     "iopub.status.busy": "2025-11-13T06:28:59.977326Z",
     "iopub.status.idle": "2025-11-13T06:29:00.294654Z",
     "shell.execute_reply": "2025-11-13T06:29:00.293816Z",
     "shell.execute_reply.started": "2025-11-13T06:28:59.977848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2bc976e30c483b95aed9d0a6842806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 60 ms, total: 172 ms\n",
      "Wall time: 307 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3, 0], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sentences = [\"Hello World\", \"Привет Мир\"]\n",
    "\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
    "encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "with torch.no_grad():\n",
    "    logits = model(**encoded_input).logits\n",
    "\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "preds = torch.argmax(probs, dim=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:29:00.295756Z",
     "iopub.status.busy": "2025-11-13T06:29:00.295414Z",
     "iopub.status.idle": "2025-11-13T06:29:00.300253Z",
     "shell.execute_reply": "2025-11-13T06:29:00.299717Z",
     "shell.execute_reply.started": "2025-11-13T06:29:00.295737Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:29:00.301080Z",
     "iopub.status.busy": "2025-11-13T06:29:00.300868Z",
     "iopub.status.idle": "2025-11-13T06:29:00.334130Z",
     "shell.execute_reply": "2025-11-13T06:29:00.333422Z",
     "shell.execute_reply.started": "2025-11-13T06:29:00.301065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9734, 0.5328, 0.5495, 1.9443])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = torch.tensor(train['target'].value_counts().sort_index().values, dtype=torch.float)\n",
    "weights = 1.0 / class_counts  \n",
    "\n",
    "weights = weights / weights.sum() * len(class_counts)  \n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:35:24.181644Z",
     "iopub.status.busy": "2025-11-13T06:35:24.181002Z",
     "iopub.status.idle": "2025-11-13T06:35:41.101253Z",
     "shell.execute_reply": "2025-11-13T06:35:41.100469Z",
     "shell.execute_reply.started": "2025-11-13T06:35:24.181593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "class PostDataset(Dataset):\n",
    "    def __init__(self, text, target=None):\n",
    "        self.text = text\n",
    "        self.encodings = tokenizer(self.text, padding=False, truncation=True, max_length=128, return_tensors=None)\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        if self.target is not None:\n",
    "            enc['labels'] = torch.tensor(self.target[idx], dtype=torch.long)\n",
    "        return enc\n",
    "\n",
    "train_ds = PostDataset(train['text'].tolist(), train['target'].tolist())\n",
    "valid_ds = PostDataset(valid['text'].tolist(), valid['target'].tolist())\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T06:35:41.102977Z",
     "iopub.status.busy": "2025-11-13T06:35:41.102699Z",
     "iopub.status.idle": "2025-11-13T06:35:42.363128Z",
     "shell.execute_reply": "2025-11-13T06:35:42.362311Z",
     "shell.execute_reply.started": "2025-11-13T06:35:41.102953Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-sentence and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "log_rate = 1\n",
    "batch_log_rate = 50\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4).to(device)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs*len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T07:04:24.547820Z",
     "iopub.status.busy": "2025-11-13T07:04:24.547515Z",
     "iopub.status.idle": "2025-11-13T07:24:46.934271Z",
     "shell.execute_reply": "2025-11-13T07:24:46.933299Z",
     "shell.execute_reply.started": "2025-11-13T07:04:24.547797Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c753e199c2a244f292568e09a2a47df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train DataLoader:   0%|          | 0/3095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/3095 | Train Loss: 1.06428\n",
      "Batch 100/3095 | Train Loss: 1.05440\n",
      "Batch 150/3095 | Train Loss: 1.04107\n",
      "Batch 200/3095 | Train Loss: 1.03342\n",
      "Batch 250/3095 | Train Loss: 1.02329\n",
      "Batch 300/3095 | Train Loss: 1.01627\n",
      "Batch 350/3095 | Train Loss: 1.00681\n",
      "Batch 400/3095 | Train Loss: 1.00745\n",
      "Batch 450/3095 | Train Loss: 1.00653\n",
      "Batch 500/3095 | Train Loss: 1.00247\n",
      "Batch 550/3095 | Train Loss: 1.00082\n",
      "Batch 600/3095 | Train Loss: 1.00022\n",
      "Batch 650/3095 | Train Loss: 0.99847\n",
      "Batch 700/3095 | Train Loss: 0.99499\n",
      "Batch 750/3095 | Train Loss: 0.99383\n",
      "Batch 800/3095 | Train Loss: 0.99374\n",
      "Batch 850/3095 | Train Loss: 0.99314\n",
      "Batch 900/3095 | Train Loss: 0.99254\n",
      "Batch 950/3095 | Train Loss: 0.99212\n",
      "Batch 1000/3095 | Train Loss: 0.99007\n",
      "Batch 1050/3095 | Train Loss: 0.98900\n",
      "Batch 1100/3095 | Train Loss: 0.98740\n",
      "Batch 1150/3095 | Train Loss: 0.98440\n",
      "Batch 1200/3095 | Train Loss: 0.98270\n",
      "Batch 1250/3095 | Train Loss: 0.98085\n",
      "Batch 1300/3095 | Train Loss: 0.98088\n",
      "Batch 1350/3095 | Train Loss: 0.97930\n",
      "Batch 1400/3095 | Train Loss: 0.97792\n",
      "Batch 1450/3095 | Train Loss: 0.97514\n",
      "Batch 1500/3095 | Train Loss: 0.97439\n",
      "Batch 1550/3095 | Train Loss: 0.97332\n",
      "Batch 1600/3095 | Train Loss: 0.97363\n",
      "Batch 1650/3095 | Train Loss: 0.97236\n",
      "Batch 1700/3095 | Train Loss: 0.97170\n",
      "Batch 1750/3095 | Train Loss: 0.96973\n",
      "Batch 1800/3095 | Train Loss: 0.96822\n",
      "Batch 1850/3095 | Train Loss: 0.96697\n",
      "Batch 1900/3095 | Train Loss: 0.96625\n",
      "Batch 1950/3095 | Train Loss: 0.96569\n",
      "Batch 2000/3095 | Train Loss: 0.96428\n",
      "Batch 2050/3095 | Train Loss: 0.96364\n",
      "Batch 2100/3095 | Train Loss: 0.96308\n",
      "Batch 2150/3095 | Train Loss: 0.96311\n",
      "Batch 2200/3095 | Train Loss: 0.96280\n",
      "Batch 2250/3095 | Train Loss: 0.96167\n",
      "Batch 2300/3095 | Train Loss: 0.96123\n",
      "Batch 2350/3095 | Train Loss: 0.96068\n",
      "Batch 2400/3095 | Train Loss: 0.96060\n",
      "Batch 2450/3095 | Train Loss: 0.95968\n",
      "Batch 2500/3095 | Train Loss: 0.95945\n",
      "Batch 2550/3095 | Train Loss: 0.95928\n",
      "Batch 2600/3095 | Train Loss: 0.95883\n",
      "Batch 2650/3095 | Train Loss: 0.95867\n",
      "Batch 2700/3095 | Train Loss: 0.95774\n",
      "Batch 2750/3095 | Train Loss: 0.95857\n",
      "Batch 2800/3095 | Train Loss: 0.95841\n",
      "Batch 2850/3095 | Train Loss: 0.95792\n",
      "Batch 2900/3095 | Train Loss: 0.95736\n",
      "Batch 2950/3095 | Train Loss: 0.95693\n",
      "Batch 3000/3095 | Train Loss: 0.95638\n",
      "Batch 3050/3095 | Train Loss: 0.95629\n",
      "Batch 3095/3095 | Train Loss: 0.95607\n",
      "Epoch 1/1 | Train Loss: 0.95607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid DataLoader:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.51900\n",
      "Diversity: [1856, 3856, 3345, 1368]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs), desc='Training'):\n",
    "    model.train()\n",
    "    running_train_loss = 0\n",
    "    all_preds = []\n",
    "    i = 0\n",
    "    for X in (pbar := tqdm(train_loader, leave=False, desc='Train DataLoader')):\n",
    "        i += 1\n",
    "        y = X['labels'].to(device)\n",
    "        X = {k: v.to(device) for k, v in X.items() if k != 'labels'}\n",
    "        logits = model(**X).logits\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        probs = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n",
    "        all_preds.extend(probs.detach().cpu().tolist())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        if i%batch_log_rate==0 or i==len(train_loader):\n",
    "            print(f\"Batch {i}/{len(train_loader)} | Train Loss: {running_train_loss/i:.5f}\")\n",
    "            # print(f\"Diversity: {torch.bincount(torch.tensor(all_preds)).tolist()}\")\n",
    "        pbar.set_postfix({'loss': f\"{running_train_loss/i:.5f}\",}) \n",
    "                          # \"diversity\": torch.bincount(torch.tensor(all_preds)).tolist()})\n",
    "        \n",
    "    if (epoch+1)%log_rate==0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {running_train_loss/i:.5f}\")\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    i = 0\n",
    "    for X in (pbar := tqdm(valid_loader, leave=False, desc='Valid DataLoader')):\n",
    "        i += 1\n",
    "        y = X['labels'].to(device)\n",
    "        X = {k: v.to(device) for k, v in X.items() if k != 'labels'}\n",
    "        with torch.no_grad():\n",
    "            logits = model(**X).logits\n",
    "        probs = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n",
    "        all_preds.extend(probs.detach().cpu().tolist())\n",
    "        all_targets.extend(y.cpu().tolist())\n",
    "    \n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    if (epoch+1)%log_rate==0:\n",
    "        print(f\"Weighted F1 Score: {f1:.5f}\")\n",
    "        print(f\"Diversity: {torch.bincount(torch.tensor(all_preds)).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T07:24:50.052928Z",
     "iopub.status.busy": "2025-11-13T07:24:50.051994Z",
     "iopub.status.idle": "2025-11-13T07:24:54.669883Z",
     "shell.execute_reply": "2025-11-13T07:24:54.668942Z",
     "shell.execute_reply.started": "2025-11-13T07:24:50.052901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_ds = PostDataset(test['text'].tolist())\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T07:24:54.671525Z",
     "iopub.status.busy": "2025-11-13T07:24:54.671269Z",
     "iopub.status.idle": "2025-11-13T07:26:31.730676Z",
     "shell.execute_reply": "2025-11-13T07:26:31.729838Z",
     "shell.execute_reply.started": "2025-11-13T07:24:54.671506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2be134b37c4e17b1cadb6cd0d7fceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test DataLoader:   0%|          | 0/807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "i = 0\n",
    "for X in (pbar := tqdm(test_loader, desc='Test DataLoader')):\n",
    "    i += 1\n",
    "    X = {k: v.to(device) for k, v in X.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**X).logits\n",
    "    probs = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n",
    "    all_preds.extend(probs.detach().cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T07:26:31.732298Z",
     "iopub.status.busy": "2025-11-13T07:26:31.732010Z",
     "iopub.status.idle": "2025-11-13T07:26:31.801490Z",
     "shell.execute_reply": "2025-11-13T07:26:31.800881Z",
     "shell.execute_reply.started": "2025-11-13T07:26:31.732279Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>relevant_plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>no_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>relevant_minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51631</th>\n",
       "      <td>51631</td>\n",
       "      <td>relevant_minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51632</th>\n",
       "      <td>51632</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51633</th>\n",
       "      <td>51633</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51634</th>\n",
       "      <td>51634</td>\n",
       "      <td>relevant_minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51635</th>\n",
       "      <td>51635</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51636 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          target\n",
       "0               0        relevant\n",
       "1               1        relevant\n",
       "2               2   relevant_plus\n",
       "3               3     no_relevant\n",
       "4               4  relevant_minus\n",
       "...           ...             ...\n",
       "51631       51631  relevant_minus\n",
       "51632       51632        relevant\n",
       "51633       51633        relevant\n",
       "51634       51634  relevant_minus\n",
       "51635       51635        relevant\n",
       "\n",
       "[51636 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm['target'] = list(map(idx2class.get, all_preds))\n",
    "subm.to_csv(\"submission.csv\", index=False)\n",
    "subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T07:26:31.802354Z",
     "iopub.status.busy": "2025-11-13T07:26:31.802163Z",
     "iopub.status.idle": "2025-11-13T07:26:31.810337Z",
     "shell.execute_reply": "2025-11-13T07:26:31.809766Z",
     "shell.execute_reply.started": "2025-11-13T07:26:31.802340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "relevant_minus    19334\n",
       "relevant          16579\n",
       "no_relevant        8842\n",
       "relevant_plus      6881\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8691299,
     "sourceId": 13713624,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
